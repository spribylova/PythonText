{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**spaCy** is a library for advanced Natural Language Processing designed in 2015 in Python and Cython. This contribution is using the basic Spacy operations with **german lexicon**.\n",
        "\n",
        "1. Matcher - search tokens in a given Text based on given criteria\n",
        "2. Word Vectors and sentence similarity - calculate cosinus similarity of 2 senetences\n",
        "\n",
        "https://spacy.io/\n",
        "\n",
        "https://spacy.pythonhumanities.com/02_02_matcher.html\n"
      ],
      "metadata": {
        "id": "KiimrXMcErSZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import libraries\n",
        "import re\n",
        "import pandas as pd\n",
        "import bs4\n",
        "import requests\n",
        "import spacy\n",
        "from spacy import displacy\n",
        "\n",
        "from spacy.matcher import Matcher\n",
        "from spacy.tokens import Span\n",
        "\n",
        "import networkx as nx\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "pd.set_option('display.max_colwidth', 200)\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "99zFA2FishIy"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download de_core_news_sm\n",
        "!python -m spacy download de_core_news_md\n",
        "!python -m spacy download de_core_news_lg\n",
        "# english: en_core_web_sm, en_core_web_md, en_core_web_lg, en_core_web_trf\n",
        "# german: de_core_news_sm, de_core_news_md, de_core_news_lg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4WknjHYDxm7",
        "outputId": "8f837d60-4957-4573-c44c-018be33d4f5b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting de-core-news-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.8.0/de_core_news_sm-3.8.0-py3-none-any.whl (14.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m64.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: de-core-news-sm\n",
            "Successfully installed de-core-news-sm-3.8.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('de_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "Collecting de-core-news-md==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_md-3.8.0/de_core_news_md-3.8.0-py3-none-any.whl (44.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: de-core-news-md\n",
            "Successfully installed de-core-news-md-3.8.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('de_core_news_md')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "Collecting de-core-news-lg==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_lg-3.8.0/de_core_news_lg-3.8.0-py3-none-any.whl (567.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m567.8/567.8 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: de-core-news-lg\n",
            "Successfully installed de-core-news-lg-3.8.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('de_core_news_lg')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Use Matcher with pattern builder**\n",
        "\n",
        "Pattern examples:\n",
        "\n",
        "ORTH, TEXT, LOWER,LENGTH,IS_ALPHA,IS_ASCII,IS_DIGIT,IS_LOWER,IS_UPPER,IS_TITLE, IS_PUNCT,IS_SPACE,IS_STOP,\n",
        "IS_SENT_START, LIKE_NUM,LIKE_URL,LIKE_EMAIL, SPACY,POS, TAG,MORPH,DEP,LEMMA, SHAPE, ENT_TYPE"
      ],
      "metadata": {
        "id": "hX_MsmQmI8SB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.lang.de.examples import sentences\n",
        "sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGw1nnjLJIEO",
        "outputId": "a8f8d473-47ef-4ad0-8bdd-b4bde00bd67e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Die ganze Stadt ist ein Startup: Shenzhen ist das Silicon Valley für Hardware-Firmen',\n",
              " 'Wie deutsche Startups die Technologie vorantreiben wollen: Künstliche Intelligenz',\n",
              " 'Trend zum Urlaub in Deutschland beschert Gastwirten mehr Umsatz',\n",
              " 'Bundesanwaltschaft erhebt Anklage gegen mutmaßlichen Schweizer Spion',\n",
              " 'San Francisco erwägt Verbot von Lieferrobotern',\n",
              " 'Autonome Fahrzeuge verlagern Haftpflicht auf Hersteller',\n",
              " 'Wo bist du?',\n",
              " 'Was ist die Hauptstadt von Deutschland?']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# search a lower case word in a text\n",
        "nlp = spacy.load(\"de_core_news_sm\")\n",
        "matcher = Matcher(nlp.vocab)\n",
        "pattern = [{\"IS_LOWER\": True}]\n",
        "matcher.add(\"bodensee\", [pattern])\n",
        "doc = nlp(\"Der Bodensee ist ein Binnengewässer im südwestlichen Mitteleuropa. Er besteht aus zwei Teilen und einem sie verbindenden Flussabschnitt des Rheins, namentlich dem Obersee, dem Seerhein und dem Untersee (mit Rheinsee, Zeller See und Gnadensee inklusive des Markelfinger Winkels). Der Bodensee liegt im Bodenseebecken, einem Teil des nördlichen Alpenvorlands; der See wird vom Rhein durchflossen: Der Zufluss heißt Alpenrhein, der Abfluss Hochrhein.\")\n",
        "matches = matcher(doc)"
      ],
      "metadata": {
        "id": "B7Au8A32riVo"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (matches)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bX5fvV-SMT2V",
        "outputId": "bbfd9d49-64cf-4f18-e514-f00a07c302a0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(60212700337922568, 2, 3), (60212700337922568, 3, 4), (60212700337922568, 5, 6), (60212700337922568, 6, 7), (60212700337922568, 10, 11), (60212700337922568, 11, 12), (60212700337922568, 12, 13), (60212700337922568, 14, 15), (60212700337922568, 15, 16), (60212700337922568, 16, 17), (60212700337922568, 17, 18), (60212700337922568, 19, 20), (60212700337922568, 22, 23), (60212700337922568, 23, 24), (60212700337922568, 26, 27), (60212700337922568, 28, 29), (60212700337922568, 29, 30), (60212700337922568, 32, 33), (60212700337922568, 37, 38), (60212700337922568, 39, 40), (60212700337922568, 40, 41), (60212700337922568, 47, 48), (60212700337922568, 48, 49), (60212700337922568, 51, 52), (60212700337922568, 53, 54), (60212700337922568, 54, 55), (60212700337922568, 57, 58), (60212700337922568, 59, 60), (60212700337922568, 60, 61), (60212700337922568, 62, 63), (60212700337922568, 66, 67), (60212700337922568, 69, 70)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (nlp.vocab[matches[0][0]].text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZuoZip22ZNE",
        "outputId": "a45d17be-4d8b-47ac-dbc0-61fb81318281"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bodensee\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save some text to txt file\n",
        "with open (\"bodensee.txt\", \"r\") as f:\n",
        "    text = f.read()"
      ],
      "metadata": {
        "id": "yDpX_4xJ5Qed"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# find nouns based on matcher pattern\n",
        "matcher = Matcher(nlp.vocab)\n",
        "pattern = [{\"POS\": \"PROPN\"}]\n",
        "matcher.add(\"PROPER_NOUNS\", [pattern])\n",
        "doc = nlp(text)\n",
        "matches = matcher(doc)\n",
        "print (len(matches))\n",
        "for match in matches[:10]:\n",
        "    print (match, doc[match[1]:match[2]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKwjg-Ec561H",
        "outputId": "c830da3e-5ad2-4473-ef52-9279f5100fd8"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60\n",
            "(3232560085755078826, 1, 2) Bodensee\n",
            "(3232560085755078826, 7, 8) Mitteleuropa\n",
            "(3232560085755078826, 20, 21) Rheins\n",
            "(3232560085755078826, 25, 26) Obersee\n",
            "(3232560085755078826, 43, 44) Untersee\n",
            "(3232560085755078826, 46, 47) Rheinsee\n",
            "(3232560085755078826, 49, 50) See\n",
            "(3232560085755078826, 51, 52) Gnadensee\n",
            "(3232560085755078826, 60, 61) Bodensee\n",
            "(3232560085755078826, 75, 76) Rhein\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# find multi word tokens based on matcher pattern\n",
        "matcher = Matcher(nlp.vocab)\n",
        "pattern = [{\"POS\": \"PROPN\", \"OP\": \"+\"}]\n",
        "matcher.add(\"PROPER_NOUNS\", [pattern])\n",
        "doc = nlp(text)\n",
        "matches = matcher(doc)\n",
        "print (len(matches))\n",
        "for match in matches[:10]:\n",
        "    print (match, doc[match[1]:match[2]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPfuCvlo566S",
        "outputId": "1f89fb04-7ab1-4fa6-fbfb-8133d2387b80"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "69\n",
            "(3232560085755078826, 1, 2) Bodensee\n",
            "(3232560085755078826, 7, 8) Mitteleuropa\n",
            "(3232560085755078826, 20, 21) Rheins\n",
            "(3232560085755078826, 25, 26) Obersee\n",
            "(3232560085755078826, 43, 44) Untersee\n",
            "(3232560085755078826, 46, 47) Rheinsee\n",
            "(3232560085755078826, 49, 50) See\n",
            "(3232560085755078826, 51, 52) Gnadensee\n",
            "(3232560085755078826, 60, 61) Bodensee\n",
            "(3232560085755078826, 75, 76) Rhein\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# use Greedy Keyword Argument¶ based on matcher pattern\n",
        "matcher = Matcher(nlp.vocab)\n",
        "pattern = [{\"POS\": \"PROPN\", \"OP\": \"+\"}]\n",
        "matcher.add(\"PROPER_NOUNS\", [pattern], greedy='LONGEST')\n",
        "doc = nlp(text)\n",
        "matches = matcher(doc)\n",
        "print (len(matches))\n",
        "for match in matches[:10]:\n",
        "    print (match, doc[match[1]:match[2]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ax90hSTk56_Z",
        "outputId": "da8c3cf2-4033-41a9-f74f-7d08658c7b35"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "52\n",
            "(3232560085755078826, 321, 324) Lacus Raetiae Brigantinus\n",
            "(3232560085755078826, 84, 86) Abfluss Hochrhein\n",
            "(3232560085755078826, 244, 246) Pomponius Mela\n",
            "(3232560085755078826, 254, 256) Lacus Venetus\n",
            "(3232560085755078826, 371, 373) Ammianus Marcellinus\n",
            "(3232560085755078826, 377, 379) Lacus Brigantiae\n",
            "(3232560085755078826, 536, 538) lacum Podamicum\n",
            "(3232560085755078826, 1, 2) Bodensee\n",
            "(3232560085755078826, 7, 8) Mitteleuropa\n",
            "(3232560085755078826, 20, 21) Rheins\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. **Word vectors**\n",
        "\n"
      ],
      "metadata": {
        "id": "mycSF8Ns9yDh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "cDq4iqh3BtXe"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"de_core_news_md\")"
      ],
      "metadata": {
        "id": "ySq2ExVb6WvI"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.A - find similar words\n",
        "your_word = \"Zitrone\"\n",
        "\n",
        "ms = nlp.vocab.vectors.most_similar(\n",
        "    np.asarray([nlp.vocab.vectors[nlp.vocab.strings[your_word]]]), n=10)\n",
        "words = [nlp.vocab.strings[w] for w in ms[0][0]]\n",
        "distances = ms[2]\n",
        "print(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bq66jqVM6W0h",
        "outputId": "3c5546ed-004a-4473-e1ca-df3a2deca27f"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Zitroneneis', 'Minzblättchen', 'Gingerol', 'Orangenzeste', 'Bittermelone', 'fenchel', 'Kochbanane', 'Zimtöl', 'Apfelessigs', 'Sellerieknolle']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.B - sentence cosinus similarity\n",
        "nlp = spacy.load(\"de_core_news_md\")  # make sure to use larger package!\n",
        "doc1 = nlp(\"Ich liebe es zu wandern und bin der Meinung, wer Berge und Seen liebt, der muss unbedingt die Wanderwege entdecken.\")\n",
        "doc2 = nlp(\"Ich mag es zu wandern. Kristallklare Seen, idyllische Wanderwege und die schönste Seenwanderungen.\")\n",
        "\n",
        "# Similarity of two documents\n",
        "print(doc1, \"<->\", doc2, doc1.similarity(doc2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mY92PBTE6W5g",
        "outputId": "001c607d-ea12-4ae1-b32c-cf81fb07c736"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ich liebe es zu wandern und bin der Meinung, wer Berge und Seen liebt, der muss unbedingt die Wanderwege entdecken. <-> Ich mag es zu wandern. Kristallklare Seen, idyllische Wanderwege und die schönste Seenwanderungen. 0.9214679002761841\n"
          ]
        }
      ]
    }
  ]
}